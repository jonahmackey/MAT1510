{"cells":[{"cell_type":"markdown","metadata":{"id":"FtxqeLwCfoH0"},"source":["**Goal**<br>\n","For a labeled dataset $\\{x_i,y_i\\}_{i=1}^N$, the Hessian of the loss is defined as\n","\n","$H = \\sum_{i=1}^N \\frac{\\partial^2 \\mathcal{}(f(x_i;\\theta),y_i)}{\\partial \\theta^2} \\in \\mathbb{R}^{p \\times p}.$\n","\n","The goal of this exercise is to train a neural network and to calculate---at the beginning and at the end of training---the spectrum of the Hessian:\n","\n","$\\{\\lambda_i(H) \\ : \\ i=1,\\dots,p\\}$.\n","\n","Our implementation will have a high runtime complexity. We will therefore:\n","* train a small network;\n","* on a subset of the MNIST dataset;\n","* and down-sample the images to $8 \\times 8$ pixels.\n","\n","*Before you start, make sure to change the runtime type to include a GPU!*\n","\n","<br>\n","\n","**Task 1 (adding 2 lines of code)**<br>\n","Implement the function *Hessian_vector_multiplication* which obtains as input a vector $v \\in \\mathbb{R}^p$ and calculates the Hessian vector multiplication, $H v \\in \\mathbb{R}^{p}$.\n","\n","Hints:\n","* read carefully the documentation of the function *torch.autograd.grad* in the following link: https://pytorch.org/docs/stable/autograd.html\n","* use the function *torch.autograd.grad* **twice**:\n","    1. first calculate the gradient, $\\frac{\\partial \\mathcal{L}(f(x_i;\\theta),y_i)}{\\partial \\theta}$\n","    2. then calculate the gradient of the gradient, i.e., the Hessian $\\frac{\\partial^2 \\mathcal{L}(f(x_i;\\theta),y_i)}{\\partial \\theta^2}$, in the direction of the vector $v$.\n","* use the functions *list_to_vector* and *vector_to_list*\n","\n","<br>\n","\n","**Task 2 (adding 3 lines of code)**<br>\n","Implement the function *get_Hessian_column*, which calculates the $i$-th column in the Hessian, using the function *Hessian_vector_multiplication*.\n","\n","Hints:\n","* to extract the $i$-th column of a matrix, one can multiply the matrix by a one-hot vector.\n","* use the variable p\n","\n","<br>\n","\n","**Task 3 (adding 1 line of code)**<br>\n","Construct the Hessian matrix using the function *get_Hessian_column*.\n","\n","Hints:\n","* use the function *torch.cat*\n","\n","<br>\n","\n","\n","**Task 4 (thinking)**<br>\n","How does the spectrum change throughout the epochs of SGD?\n","\n","<br>\n","\n","**Submission**<br>\n","*   Download your code by clicking File -> Download .ipynb\n","*   Submit your downloaded code on Quercus together with a PDF file of your code."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_UD01rkIfnvP"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from torchvision import datasets, transforms\n","\n","import matplotlib.pyplot as plt\n","\n","from scipy.sparse.linalg import svds\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8B32E9KfrHB"},"outputs":[],"source":["# hyperparameters\n","device          = \"cuda\"\n","epochs          = 100\n","lr              = 0.1\n","batch_size      = 128\n","momentum        = 0.9\n","weight_decay    = 5e-4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QrJAdNqOfs-5"},"outputs":[],"source":["# model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        \n","        self.fc1 = nn.Linear(8**2, 10)\n","        self.fc2 = nn.Linear(10, 10)\n","        \n","    def forward(self, x):\n","        x = x.view(x.shape[0], -1)\n","        return self.fc2(F.relu(self.fc1(x)))\n","\n","# dataset\n","transform = transforms.Compose([transforms.Resize(8),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize(0.1307,0.3081)])\n","\n","dataset = datasets.MNIST('../data', download=True, train=True, transform=transform)\n","\n","# subsample dataset\n","subset = torch.utils.data.Subset(dataset, range(0, len(dataset), 100))\n","\n","train_loader = torch.utils.data.DataLoader(subset, batch_size=batch_size,\n","                                           shuffle=True, drop_last=True)\n","\n","train_loader_2 = torch.utils.data.DataLoader(subset, batch_size=batch_size,\n","                                             shuffle=True, drop_last=False)\n","\n","# loss function\n","loss_function = nn.CrossEntropyLoss()\n","\n","loss_function_2 = nn.CrossEntropyLoss(reduction='sum')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":166788,"status":"ok","timestamp":1668470561577,"user":{"displayName":"Jonah Mackey","userId":"12759283407912189532"},"user_tz":300},"id":"2ddQpjf9ft5c","outputId":"c2027e86-52d7-49d9-bd8b-ded2da1b3d95"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: UserWarning: torch.eig is deprecated in favor of torch.linalg.eig and will be removed in a future PyTorch release.\n","torch.linalg.eig returns complex tensors of dtype cfloat or cdouble rather than real tensors mimicking complex tensors.\n","L, _ = torch.eig(A)\n","should be replaced with\n","L_complex = torch.linalg.eigvals(A)\n","and\n","L, V = torch.eig(A, eigenvectors=True)\n","should be replaced with\n","L_complex, V_complex = torch.linalg.eig(A) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:3415.)\n"]},{"name":"stdout","output_type":"stream","text":["Train\t\tEpoch: 1 \tBatch 1/4 (25%) \tBatch Loss: 2.332540 \tBatch Accuracy: 5.468750\n","Train\t\tEpoch: 1 \tBatch 2/4 (50%) \tBatch Loss: 2.306489 \tBatch Accuracy: 8.203125\n","Train\t\tEpoch: 1 \tBatch 3/4 (75%) \tBatch Loss: 2.295761 \tBatch Accuracy: 8.854167\n","Train\t\tEpoch: 1 \tBatch 4/4 (100%) \tBatch Loss: 2.274896 \tBatch Accuracy: 8.984375\n","Train\t\tEpoch: 2 \tBatch 1/4 (25%) \tBatch Loss: 2.246039 \tBatch Accuracy: 14.843750\n","Train\t\tEpoch: 2 \tBatch 2/4 (50%) \tBatch Loss: 2.207152 \tBatch Accuracy: 14.843750\n","Train\t\tEpoch: 2 \tBatch 3/4 (75%) \tBatch Loss: 2.165953 \tBatch Accuracy: 21.093750\n","Train\t\tEpoch: 2 \tBatch 4/4 (100%) \tBatch Loss: 2.128078 \tBatch Accuracy: 23.437500\n","Train\t\tEpoch: 3 \tBatch 1/4 (25%) \tBatch Loss: 2.057085 \tBatch Accuracy: 38.281250\n","Train\t\tEpoch: 3 \tBatch 2/4 (50%) \tBatch Loss: 2.045124 \tBatch Accuracy: 35.156250\n","Train\t\tEpoch: 3 \tBatch 3/4 (75%) \tBatch Loss: 1.973678 \tBatch Accuracy: 35.937500\n","Train\t\tEpoch: 3 \tBatch 4/4 (100%) \tBatch Loss: 1.979944 \tBatch Accuracy: 34.570312\n","Train\t\tEpoch: 4 \tBatch 1/4 (25%) \tBatch Loss: 1.810570 \tBatch Accuracy: 48.437500\n","Train\t\tEpoch: 4 \tBatch 2/4 (50%) \tBatch Loss: 1.779187 \tBatch Accuracy: 49.218750\n","Train\t\tEpoch: 4 \tBatch 3/4 (75%) \tBatch Loss: 1.699683 \tBatch Accuracy: 50.260417\n","Train\t\tEpoch: 4 \tBatch 4/4 (100%) \tBatch Loss: 1.715778 \tBatch Accuracy: 50.390625\n","Train\t\tEpoch: 5 \tBatch 1/4 (25%) \tBatch Loss: 1.514877 \tBatch Accuracy: 69.531250\n","Train\t\tEpoch: 5 \tBatch 2/4 (50%) \tBatch Loss: 1.430695 \tBatch Accuracy: 68.750000\n","Train\t\tEpoch: 5 \tBatch 3/4 (75%) \tBatch Loss: 1.353243 \tBatch Accuracy: 66.927083\n","Train\t\tEpoch: 5 \tBatch 4/4 (100%) \tBatch Loss: 1.284663 \tBatch Accuracy: 67.187500\n","Train\t\tEpoch: 6 \tBatch 1/4 (25%) \tBatch Loss: 1.056020 \tBatch Accuracy: 78.125000\n","Train\t\tEpoch: 6 \tBatch 2/4 (50%) \tBatch Loss: 0.995635 \tBatch Accuracy: 78.906250\n","Train\t\tEpoch: 6 \tBatch 3/4 (75%) \tBatch Loss: 1.115097 \tBatch Accuracy: 74.479167\n","Train\t\tEpoch: 6 \tBatch 4/4 (100%) \tBatch Loss: 0.896109 \tBatch Accuracy: 74.023438\n","Train\t\tEpoch: 7 \tBatch 1/4 (25%) \tBatch Loss: 0.740777 \tBatch Accuracy: 78.125000\n","Train\t\tEpoch: 7 \tBatch 2/4 (50%) \tBatch Loss: 0.939488 \tBatch Accuracy: 76.171875\n","Train\t\tEpoch: 7 \tBatch 3/4 (75%) \tBatch Loss: 0.766052 \tBatch Accuracy: 76.302083\n","Train\t\tEpoch: 7 \tBatch 4/4 (100%) \tBatch Loss: 0.702229 \tBatch Accuracy: 76.171875\n","Train\t\tEpoch: 8 \tBatch 1/4 (25%) \tBatch Loss: 0.647072 \tBatch Accuracy: 78.906250\n","Train\t\tEpoch: 8 \tBatch 2/4 (50%) \tBatch Loss: 0.855450 \tBatch Accuracy: 74.218750\n","Train\t\tEpoch: 8 \tBatch 3/4 (75%) \tBatch Loss: 0.596727 \tBatch Accuracy: 77.604167\n","Train\t\tEpoch: 8 \tBatch 4/4 (100%) \tBatch Loss: 0.640604 \tBatch Accuracy: 77.539062\n","Train\t\tEpoch: 9 \tBatch 1/4 (25%) \tBatch Loss: 0.685792 \tBatch Accuracy: 80.468750\n","Train\t\tEpoch: 9 \tBatch 2/4 (50%) \tBatch Loss: 0.549825 \tBatch Accuracy: 80.859375\n","Train\t\tEpoch: 9 \tBatch 3/4 (75%) \tBatch Loss: 0.687737 \tBatch Accuracy: 79.166667\n","Train\t\tEpoch: 9 \tBatch 4/4 (100%) \tBatch Loss: 0.646498 \tBatch Accuracy: 78.906250\n","Train\t\tEpoch: 10 \tBatch 1/4 (25%) \tBatch Loss: 0.565008 \tBatch Accuracy: 82.031250\n","Train\t\tEpoch: 10 \tBatch 2/4 (50%) \tBatch Loss: 0.511196 \tBatch Accuracy: 83.593750\n","Train\t\tEpoch: 10 \tBatch 3/4 (75%) \tBatch Loss: 0.582985 \tBatch Accuracy: 82.291667\n","Train\t\tEpoch: 10 \tBatch 4/4 (100%) \tBatch Loss: 0.588821 \tBatch Accuracy: 82.226562\n","Train\t\tEpoch: 11 \tBatch 1/4 (25%) \tBatch Loss: 0.531021 \tBatch Accuracy: 83.593750\n","Train\t\tEpoch: 11 \tBatch 2/4 (50%) \tBatch Loss: 0.492748 \tBatch Accuracy: 82.421875\n","Train\t\tEpoch: 11 \tBatch 3/4 (75%) \tBatch Loss: 0.614871 \tBatch Accuracy: 82.552083\n","Train\t\tEpoch: 11 \tBatch 4/4 (100%) \tBatch Loss: 0.573220 \tBatch Accuracy: 82.812500\n","Train\t\tEpoch: 12 \tBatch 1/4 (25%) \tBatch Loss: 0.636592 \tBatch Accuracy: 79.687500\n","Train\t\tEpoch: 12 \tBatch 2/4 (50%) \tBatch Loss: 0.373986 \tBatch Accuracy: 82.031250\n","Train\t\tEpoch: 12 \tBatch 3/4 (75%) \tBatch Loss: 0.471364 \tBatch Accuracy: 82.031250\n","Train\t\tEpoch: 12 \tBatch 4/4 (100%) \tBatch Loss: 0.494148 \tBatch Accuracy: 83.398438\n","Train\t\tEpoch: 13 \tBatch 1/4 (25%) \tBatch Loss: 0.388252 \tBatch Accuracy: 86.718750\n","Train\t\tEpoch: 13 \tBatch 2/4 (50%) \tBatch Loss: 0.409696 \tBatch Accuracy: 87.500000\n","Train\t\tEpoch: 13 \tBatch 3/4 (75%) \tBatch Loss: 0.437869 \tBatch Accuracy: 86.979167\n","Train\t\tEpoch: 13 \tBatch 4/4 (100%) \tBatch Loss: 0.637596 \tBatch Accuracy: 85.156250\n","Train\t\tEpoch: 14 \tBatch 1/4 (25%) \tBatch Loss: 0.429831 \tBatch Accuracy: 86.718750\n","Train\t\tEpoch: 14 \tBatch 2/4 (50%) \tBatch Loss: 0.375742 \tBatch Accuracy: 86.328125\n","Train\t\tEpoch: 14 \tBatch 3/4 (75%) \tBatch Loss: 0.533562 \tBatch Accuracy: 85.156250\n","Train\t\tEpoch: 14 \tBatch 4/4 (100%) \tBatch Loss: 0.443374 \tBatch Accuracy: 86.132812\n","Train\t\tEpoch: 15 \tBatch 1/4 (25%) \tBatch Loss: 0.432552 \tBatch Accuracy: 86.718750\n","Train\t\tEpoch: 15 \tBatch 2/4 (50%) \tBatch Loss: 0.470618 \tBatch Accuracy: 88.671875\n","Train\t\tEpoch: 15 \tBatch 3/4 (75%) \tBatch Loss: 0.372440 \tBatch Accuracy: 88.802083\n","Train\t\tEpoch: 15 \tBatch 4/4 (100%) \tBatch Loss: 0.320866 \tBatch Accuracy: 88.867188\n","Train\t\tEpoch: 16 \tBatch 1/4 (25%) \tBatch Loss: 0.413247 \tBatch Accuracy: 85.156250\n","Train\t\tEpoch: 16 \tBatch 2/4 (50%) \tBatch Loss: 0.357994 \tBatch Accuracy: 84.765625\n","Train\t\tEpoch: 16 \tBatch 3/4 (75%) \tBatch Loss: 0.453425 \tBatch Accuracy: 83.854167\n","Train\t\tEpoch: 16 \tBatch 4/4 (100%) \tBatch Loss: 0.361969 \tBatch Accuracy: 85.546875\n","Train\t\tEpoch: 17 \tBatch 1/4 (25%) \tBatch Loss: 0.362829 \tBatch Accuracy: 85.937500\n","Train\t\tEpoch: 17 \tBatch 2/4 (50%) \tBatch Loss: 0.428871 \tBatch Accuracy: 86.328125\n","Train\t\tEpoch: 17 \tBatch 3/4 (75%) \tBatch Loss: 0.460044 \tBatch Accuracy: 86.458333\n","Train\t\tEpoch: 17 \tBatch 4/4 (100%) \tBatch Loss: 0.275067 \tBatch Accuracy: 87.695312\n","Train\t\tEpoch: 18 \tBatch 1/4 (25%) \tBatch Loss: 0.299870 \tBatch Accuracy: 91.406250\n","Train\t\tEpoch: 18 \tBatch 2/4 (50%) \tBatch Loss: 0.446824 \tBatch Accuracy: 87.500000\n","Train\t\tEpoch: 18 \tBatch 3/4 (75%) \tBatch Loss: 0.391744 \tBatch Accuracy: 86.979167\n","Train\t\tEpoch: 18 \tBatch 4/4 (100%) \tBatch Loss: 0.335197 \tBatch Accuracy: 86.523438\n","Train\t\tEpoch: 19 \tBatch 1/4 (25%) \tBatch Loss: 0.314871 \tBatch Accuracy: 90.625000\n","Train\t\tEpoch: 19 \tBatch 2/4 (50%) \tBatch Loss: 0.376447 \tBatch Accuracy: 91.406250\n","Train\t\tEpoch: 19 \tBatch 3/4 (75%) \tBatch Loss: 0.415268 \tBatch Accuracy: 90.104167\n","Train\t\tEpoch: 19 \tBatch 4/4 (100%) \tBatch Loss: 0.499153 \tBatch Accuracy: 88.671875\n","Train\t\tEpoch: 20 \tBatch 1/4 (25%) \tBatch Loss: 0.397160 \tBatch Accuracy: 84.375000\n","Train\t\tEpoch: 20 \tBatch 2/4 (50%) \tBatch Loss: 0.215911 \tBatch Accuracy: 88.671875\n","Train\t\tEpoch: 20 \tBatch 3/4 (75%) \tBatch Loss: 0.371794 \tBatch Accuracy: 87.760417\n","Train\t\tEpoch: 20 \tBatch 4/4 (100%) \tBatch Loss: 0.463400 \tBatch Accuracy: 87.500000\n","Train\t\tEpoch: 21 \tBatch 1/4 (25%) \tBatch Loss: 0.327612 \tBatch Accuracy: 87.500000\n","Train\t\tEpoch: 21 \tBatch 2/4 (50%) \tBatch Loss: 0.301105 \tBatch Accuracy: 89.843750\n","Train\t\tEpoch: 21 \tBatch 3/4 (75%) \tBatch Loss: 0.386112 \tBatch Accuracy: 88.541667\n","Train\t\tEpoch: 21 \tBatch 4/4 (100%) \tBatch Loss: 0.376699 \tBatch Accuracy: 89.257812\n","Train\t\tEpoch: 22 \tBatch 1/4 (25%) \tBatch Loss: 0.336479 \tBatch Accuracy: 89.843750\n","Train\t\tEpoch: 22 \tBatch 2/4 (50%) \tBatch Loss: 0.377158 \tBatch Accuracy: 88.671875\n","Train\t\tEpoch: 22 \tBatch 3/4 (75%) \tBatch Loss: 0.377306 \tBatch Accuracy: 87.500000\n","Train\t\tEpoch: 22 \tBatch 4/4 (100%) \tBatch Loss: 0.297342 \tBatch Accuracy: 88.281250\n","Train\t\tEpoch: 23 \tBatch 1/4 (25%) \tBatch Loss: 0.335676 \tBatch Accuracy: 87.500000\n","Train\t\tEpoch: 23 \tBatch 2/4 (50%) \tBatch Loss: 0.312692 \tBatch Accuracy: 89.453125\n","Train\t\tEpoch: 23 \tBatch 3/4 (75%) \tBatch Loss: 0.367783 \tBatch Accuracy: 89.322917\n","Train\t\tEpoch: 23 \tBatch 4/4 (100%) \tBatch Loss: 0.327752 \tBatch Accuracy: 89.257812\n","Train\t\tEpoch: 24 \tBatch 1/4 (25%) \tBatch Loss: 0.377248 \tBatch Accuracy: 89.062500\n","Train\t\tEpoch: 24 \tBatch 2/4 (50%) \tBatch Loss: 0.262014 \tBatch Accuracy: 89.453125\n","Train\t\tEpoch: 24 \tBatch 3/4 (75%) \tBatch Loss: 0.349481 \tBatch Accuracy: 89.322917\n","Train\t\tEpoch: 24 \tBatch 4/4 (100%) \tBatch Loss: 0.231606 \tBatch Accuracy: 90.039062\n","Train\t\tEpoch: 25 \tBatch 1/4 (25%) \tBatch Loss: 0.290261 \tBatch Accuracy: 89.062500\n","Train\t\tEpoch: 25 \tBatch 2/4 (50%) \tBatch Loss: 0.241166 \tBatch Accuracy: 89.843750\n","Train\t\tEpoch: 25 \tBatch 3/4 (75%) \tBatch Loss: 0.250536 \tBatch Accuracy: 90.625000\n","Train\t\tEpoch: 25 \tBatch 4/4 (100%) \tBatch Loss: 0.260348 \tBatch Accuracy: 91.601562\n","Train\t\tEpoch: 26 \tBatch 1/4 (25%) \tBatch Loss: 0.228406 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 26 \tBatch 2/4 (50%) \tBatch Loss: 0.309473 \tBatch Accuracy: 93.750000\n","Train\t\tEpoch: 26 \tBatch 3/4 (75%) \tBatch Loss: 0.329390 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 26 \tBatch 4/4 (100%) \tBatch Loss: 0.234563 \tBatch Accuracy: 92.773438\n","Train\t\tEpoch: 27 \tBatch 1/4 (25%) \tBatch Loss: 0.173292 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 27 \tBatch 2/4 (50%) \tBatch Loss: 0.245204 \tBatch Accuracy: 93.359375\n","Train\t\tEpoch: 27 \tBatch 3/4 (75%) \tBatch Loss: 0.282180 \tBatch Accuracy: 92.187500\n","Train\t\tEpoch: 27 \tBatch 4/4 (100%) \tBatch Loss: 0.368501 \tBatch Accuracy: 90.820312\n","Train\t\tEpoch: 28 \tBatch 1/4 (25%) \tBatch Loss: 0.145670 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 28 \tBatch 2/4 (50%) \tBatch Loss: 0.285089 \tBatch Accuracy: 94.140625\n","Train\t\tEpoch: 28 \tBatch 3/4 (75%) \tBatch Loss: 0.278966 \tBatch Accuracy: 93.489583\n","Train\t\tEpoch: 28 \tBatch 4/4 (100%) \tBatch Loss: 0.261623 \tBatch Accuracy: 93.554688\n","Train\t\tEpoch: 29 \tBatch 1/4 (25%) \tBatch Loss: 0.220883 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 29 \tBatch 2/4 (50%) \tBatch Loss: 0.219084 \tBatch Accuracy: 93.359375\n","Train\t\tEpoch: 29 \tBatch 3/4 (75%) \tBatch Loss: 0.305090 \tBatch Accuracy: 92.187500\n","Train\t\tEpoch: 29 \tBatch 4/4 (100%) \tBatch Loss: 0.202081 \tBatch Accuracy: 92.578125\n","Train\t\tEpoch: 30 \tBatch 1/4 (25%) \tBatch Loss: 0.303446 \tBatch Accuracy: 89.062500\n","Train\t\tEpoch: 30 \tBatch 2/4 (50%) \tBatch Loss: 0.232421 \tBatch Accuracy: 90.234375\n","Train\t\tEpoch: 30 \tBatch 3/4 (75%) \tBatch Loss: 0.196921 \tBatch Accuracy: 91.406250\n","Train\t\tEpoch: 30 \tBatch 4/4 (100%) \tBatch Loss: 0.300599 \tBatch Accuracy: 91.015625\n","Train\t\tEpoch: 31 \tBatch 1/4 (25%) \tBatch Loss: 0.157669 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 31 \tBatch 2/4 (50%) \tBatch Loss: 0.215180 \tBatch Accuracy: 95.703125\n","Train\t\tEpoch: 31 \tBatch 3/4 (75%) \tBatch Loss: 0.254235 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 31 \tBatch 4/4 (100%) \tBatch Loss: 0.255275 \tBatch Accuracy: 94.921875\n","Train\t\tEpoch: 32 \tBatch 1/4 (25%) \tBatch Loss: 0.150652 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 32 \tBatch 2/4 (50%) \tBatch Loss: 0.302428 \tBatch Accuracy: 93.750000\n","Train\t\tEpoch: 32 \tBatch 3/4 (75%) \tBatch Loss: 0.226015 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 32 \tBatch 4/4 (100%) \tBatch Loss: 0.193017 \tBatch Accuracy: 93.164062\n","Train\t\tEpoch: 33 \tBatch 1/4 (25%) \tBatch Loss: 0.189173 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 33 \tBatch 2/4 (50%) \tBatch Loss: 0.266098 \tBatch Accuracy: 94.921875\n","Train\t\tEpoch: 33 \tBatch 3/4 (75%) \tBatch Loss: 0.208827 \tBatch Accuracy: 95.572917\n","Train\t\tEpoch: 33 \tBatch 4/4 (100%) \tBatch Loss: 0.196600 \tBatch Accuracy: 94.726562\n","Train\t\tEpoch: 34 \tBatch 1/4 (25%) \tBatch Loss: 0.300061 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 34 \tBatch 2/4 (50%) \tBatch Loss: 0.215785 \tBatch Accuracy: 93.750000\n","Train\t\tEpoch: 34 \tBatch 3/4 (75%) \tBatch Loss: 0.224021 \tBatch Accuracy: 93.750000\n","Train\t\tEpoch: 34 \tBatch 4/4 (100%) \tBatch Loss: 0.166859 \tBatch Accuracy: 93.945312\n","Train\t\tEpoch: 35 \tBatch 1/4 (25%) \tBatch Loss: 0.220435 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 35 \tBatch 2/4 (50%) \tBatch Loss: 0.187483 \tBatch Accuracy: 93.359375\n","Train\t\tEpoch: 35 \tBatch 3/4 (75%) \tBatch Loss: 0.233116 \tBatch Accuracy: 93.750000\n","Train\t\tEpoch: 35 \tBatch 4/4 (100%) \tBatch Loss: 0.219039 \tBatch Accuracy: 93.945312\n","Train\t\tEpoch: 36 \tBatch 1/4 (25%) \tBatch Loss: 0.348035 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 36 \tBatch 2/4 (50%) \tBatch Loss: 0.199136 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 36 \tBatch 3/4 (75%) \tBatch Loss: 0.158214 \tBatch Accuracy: 94.270833\n","Train\t\tEpoch: 36 \tBatch 4/4 (100%) \tBatch Loss: 0.187962 \tBatch Accuracy: 94.726562\n","Train\t\tEpoch: 37 \tBatch 1/4 (25%) \tBatch Loss: 0.271484 \tBatch Accuracy: 92.187500\n","Train\t\tEpoch: 37 \tBatch 2/4 (50%) \tBatch Loss: 0.255831 \tBatch Accuracy: 92.187500\n","Train\t\tEpoch: 37 \tBatch 3/4 (75%) \tBatch Loss: 0.119730 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 37 \tBatch 4/4 (100%) \tBatch Loss: 0.194400 \tBatch Accuracy: 94.335938\n","Train\t\tEpoch: 38 \tBatch 1/4 (25%) \tBatch Loss: 0.245919 \tBatch Accuracy: 90.625000\n","Train\t\tEpoch: 38 \tBatch 2/4 (50%) \tBatch Loss: 0.244826 \tBatch Accuracy: 92.578125\n","Train\t\tEpoch: 38 \tBatch 3/4 (75%) \tBatch Loss: 0.216972 \tBatch Accuracy: 93.229167\n","Train\t\tEpoch: 38 \tBatch 4/4 (100%) \tBatch Loss: 0.245028 \tBatch Accuracy: 93.359375\n","Train\t\tEpoch: 39 \tBatch 1/4 (25%) \tBatch Loss: 0.251756 \tBatch Accuracy: 90.625000\n","Train\t\tEpoch: 39 \tBatch 2/4 (50%) \tBatch Loss: 0.129833 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 39 \tBatch 3/4 (75%) \tBatch Loss: 0.265005 \tBatch Accuracy: 94.010417\n","Train\t\tEpoch: 39 \tBatch 4/4 (100%) \tBatch Loss: 0.204470 \tBatch Accuracy: 93.945312\n","Train\t\tEpoch: 40 \tBatch 1/4 (25%) \tBatch Loss: 0.099119 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 40 \tBatch 2/4 (50%) \tBatch Loss: 0.202734 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 40 \tBatch 3/4 (75%) \tBatch Loss: 0.245239 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 40 \tBatch 4/4 (100%) \tBatch Loss: 0.231679 \tBatch Accuracy: 95.117188\n","Train\t\tEpoch: 41 \tBatch 1/4 (25%) \tBatch Loss: 0.110904 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 41 \tBatch 2/4 (50%) \tBatch Loss: 0.211915 \tBatch Accuracy: 95.703125\n","Train\t\tEpoch: 41 \tBatch 3/4 (75%) \tBatch Loss: 0.230557 \tBatch Accuracy: 94.270833\n","Train\t\tEpoch: 41 \tBatch 4/4 (100%) \tBatch Loss: 0.215458 \tBatch Accuracy: 93.750000\n","Train\t\tEpoch: 42 \tBatch 1/4 (25%) \tBatch Loss: 0.210795 \tBatch Accuracy: 92.187500\n","Train\t\tEpoch: 42 \tBatch 2/4 (50%) \tBatch Loss: 0.131839 \tBatch Accuracy: 94.921875\n","Train\t\tEpoch: 42 \tBatch 3/4 (75%) \tBatch Loss: 0.184218 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 42 \tBatch 4/4 (100%) \tBatch Loss: 0.119139 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 43 \tBatch 1/4 (25%) \tBatch Loss: 0.168819 \tBatch Accuracy: 93.750000\n","Train\t\tEpoch: 43 \tBatch 2/4 (50%) \tBatch Loss: 0.224085 \tBatch Accuracy: 94.140625\n","Train\t\tEpoch: 43 \tBatch 3/4 (75%) \tBatch Loss: 0.183344 \tBatch Accuracy: 94.791667\n","Train\t\tEpoch: 43 \tBatch 4/4 (100%) \tBatch Loss: 0.164224 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 44 \tBatch 1/4 (25%) \tBatch Loss: 0.231950 \tBatch Accuracy: 92.187500\n","Train\t\tEpoch: 44 \tBatch 2/4 (50%) \tBatch Loss: 0.160244 \tBatch Accuracy: 93.750000\n","Train\t\tEpoch: 44 \tBatch 3/4 (75%) \tBatch Loss: 0.147794 \tBatch Accuracy: 94.791667\n","Train\t\tEpoch: 44 \tBatch 4/4 (100%) \tBatch Loss: 0.178419 \tBatch Accuracy: 94.726562\n","Train\t\tEpoch: 45 \tBatch 1/4 (25%) \tBatch Loss: 0.177141 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 45 \tBatch 2/4 (50%) \tBatch Loss: 0.235090 \tBatch Accuracy: 92.187500\n","Train\t\tEpoch: 45 \tBatch 3/4 (75%) \tBatch Loss: 0.159195 \tBatch Accuracy: 93.229167\n","Train\t\tEpoch: 45 \tBatch 4/4 (100%) \tBatch Loss: 0.198115 \tBatch Accuracy: 94.140625\n","Train\t\tEpoch: 46 \tBatch 1/4 (25%) \tBatch Loss: 0.190980 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 46 \tBatch 2/4 (50%) \tBatch Loss: 0.256172 \tBatch Accuracy: 94.140625\n","Train\t\tEpoch: 46 \tBatch 3/4 (75%) \tBatch Loss: 0.130891 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 46 \tBatch 4/4 (100%) \tBatch Loss: 0.135767 \tBatch Accuracy: 95.703125\n","Train\t\tEpoch: 47 \tBatch 1/4 (25%) \tBatch Loss: 0.155145 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 47 \tBatch 2/4 (50%) \tBatch Loss: 0.193051 \tBatch Accuracy: 96.484375\n","Train\t\tEpoch: 47 \tBatch 3/4 (75%) \tBatch Loss: 0.208587 \tBatch Accuracy: 94.791667\n","Train\t\tEpoch: 47 \tBatch 4/4 (100%) \tBatch Loss: 0.168449 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 48 \tBatch 1/4 (25%) \tBatch Loss: 0.142152 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 48 \tBatch 2/4 (50%) \tBatch Loss: 0.178894 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 48 \tBatch 3/4 (75%) \tBatch Loss: 0.158255 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 48 \tBatch 4/4 (100%) \tBatch Loss: 0.196117 \tBatch Accuracy: 95.703125\n","Train\t\tEpoch: 49 \tBatch 1/4 (25%) \tBatch Loss: 0.136936 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 49 \tBatch 2/4 (50%) \tBatch Loss: 0.213504 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 49 \tBatch 3/4 (75%) \tBatch Loss: 0.178755 \tBatch Accuracy: 95.572917\n","Train\t\tEpoch: 49 \tBatch 4/4 (100%) \tBatch Loss: 0.165990 \tBatch Accuracy: 95.703125\n","Train\t\tEpoch: 50 \tBatch 1/4 (25%) \tBatch Loss: 0.133913 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 50 \tBatch 2/4 (50%) \tBatch Loss: 0.187775 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 50 \tBatch 3/4 (75%) \tBatch Loss: 0.218217 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 50 \tBatch 4/4 (100%) \tBatch Loss: 0.171078 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 51 \tBatch 1/4 (25%) \tBatch Loss: 0.237363 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 51 \tBatch 2/4 (50%) \tBatch Loss: 0.165906 \tBatch Accuracy: 94.140625\n","Train\t\tEpoch: 51 \tBatch 3/4 (75%) \tBatch Loss: 0.137632 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 51 \tBatch 4/4 (100%) \tBatch Loss: 0.089616 \tBatch Accuracy: 95.898438\n","Train\t\tEpoch: 52 \tBatch 1/4 (25%) \tBatch Loss: 0.253026 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 52 \tBatch 2/4 (50%) \tBatch Loss: 0.128439 \tBatch Accuracy: 94.140625\n","Train\t\tEpoch: 52 \tBatch 3/4 (75%) \tBatch Loss: 0.164433 \tBatch Accuracy: 94.010417\n","Train\t\tEpoch: 52 \tBatch 4/4 (100%) \tBatch Loss: 0.116051 \tBatch Accuracy: 94.921875\n","Train\t\tEpoch: 53 \tBatch 1/4 (25%) \tBatch Loss: 0.148674 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 53 \tBatch 2/4 (50%) \tBatch Loss: 0.148298 \tBatch Accuracy: 96.484375\n","Train\t\tEpoch: 53 \tBatch 3/4 (75%) \tBatch Loss: 0.102963 \tBatch Accuracy: 97.135417\n","Train\t\tEpoch: 53 \tBatch 4/4 (100%) \tBatch Loss: 0.321962 \tBatch Accuracy: 95.703125\n","Train\t\tEpoch: 54 \tBatch 1/4 (25%) \tBatch Loss: 0.135523 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 54 \tBatch 2/4 (50%) \tBatch Loss: 0.167906 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 54 \tBatch 3/4 (75%) \tBatch Loss: 0.163251 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 54 \tBatch 4/4 (100%) \tBatch Loss: 0.186175 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 55 \tBatch 1/4 (25%) \tBatch Loss: 0.158774 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 55 \tBatch 2/4 (50%) \tBatch Loss: 0.143341 \tBatch Accuracy: 94.921875\n","Train\t\tEpoch: 55 \tBatch 3/4 (75%) \tBatch Loss: 0.217442 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 55 \tBatch 4/4 (100%) \tBatch Loss: 0.129484 \tBatch Accuracy: 95.117188\n","Train\t\tEpoch: 56 \tBatch 1/4 (25%) \tBatch Loss: 0.154274 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 56 \tBatch 2/4 (50%) \tBatch Loss: 0.123184 \tBatch Accuracy: 96.484375\n","Train\t\tEpoch: 56 \tBatch 3/4 (75%) \tBatch Loss: 0.179235 \tBatch Accuracy: 95.833333\n","Train\t\tEpoch: 56 \tBatch 4/4 (100%) \tBatch Loss: 0.175847 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 57 \tBatch 1/4 (25%) \tBatch Loss: 0.202735 \tBatch Accuracy: 92.968750\n","Train\t\tEpoch: 57 \tBatch 2/4 (50%) \tBatch Loss: 0.123605 \tBatch Accuracy: 95.703125\n","Train\t\tEpoch: 57 \tBatch 3/4 (75%) \tBatch Loss: 0.219397 \tBatch Accuracy: 95.833333\n","Train\t\tEpoch: 57 \tBatch 4/4 (100%) \tBatch Loss: 0.168543 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 58 \tBatch 1/4 (25%) \tBatch Loss: 0.110246 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 58 \tBatch 2/4 (50%) \tBatch Loss: 0.229369 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 58 \tBatch 3/4 (75%) \tBatch Loss: 0.153349 \tBatch Accuracy: 95.572917\n","Train\t\tEpoch: 58 \tBatch 4/4 (100%) \tBatch Loss: 0.109540 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 59 \tBatch 1/4 (25%) \tBatch Loss: 0.122252 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 59 \tBatch 2/4 (50%) \tBatch Loss: 0.206590 \tBatch Accuracy: 94.921875\n","Train\t\tEpoch: 59 \tBatch 3/4 (75%) \tBatch Loss: 0.125049 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 59 \tBatch 4/4 (100%) \tBatch Loss: 0.156943 \tBatch Accuracy: 95.507812\n","Train\t\tEpoch: 60 \tBatch 1/4 (25%) \tBatch Loss: 0.115929 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 60 \tBatch 2/4 (50%) \tBatch Loss: 0.158390 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 60 \tBatch 3/4 (75%) \tBatch Loss: 0.130331 \tBatch Accuracy: 96.354167\n","Train\t\tEpoch: 60 \tBatch 4/4 (100%) \tBatch Loss: 0.184839 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 61 \tBatch 1/4 (25%) \tBatch Loss: 0.177118 \tBatch Accuracy: 92.187500\n","Train\t\tEpoch: 61 \tBatch 2/4 (50%) \tBatch Loss: 0.115568 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 61 \tBatch 3/4 (75%) \tBatch Loss: 0.111965 \tBatch Accuracy: 95.572917\n","Train\t\tEpoch: 61 \tBatch 4/4 (100%) \tBatch Loss: 0.204998 \tBatch Accuracy: 95.898438\n","Train\t\tEpoch: 62 \tBatch 1/4 (25%) \tBatch Loss: 0.154064 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 62 \tBatch 2/4 (50%) \tBatch Loss: 0.096451 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 62 \tBatch 3/4 (75%) \tBatch Loss: 0.107036 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 62 \tBatch 4/4 (100%) \tBatch Loss: 0.221142 \tBatch Accuracy: 95.898438\n","Train\t\tEpoch: 63 \tBatch 1/4 (25%) \tBatch Loss: 0.105754 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 63 \tBatch 2/4 (50%) \tBatch Loss: 0.122609 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 63 \tBatch 3/4 (75%) \tBatch Loss: 0.212762 \tBatch Accuracy: 95.833333\n","Train\t\tEpoch: 63 \tBatch 4/4 (100%) \tBatch Loss: 0.126381 \tBatch Accuracy: 95.898438\n","Train\t\tEpoch: 64 \tBatch 1/4 (25%) \tBatch Loss: 0.149594 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 64 \tBatch 2/4 (50%) \tBatch Loss: 0.112267 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 64 \tBatch 3/4 (75%) \tBatch Loss: 0.162986 \tBatch Accuracy: 97.135417\n","Train\t\tEpoch: 64 \tBatch 4/4 (100%) \tBatch Loss: 0.128127 \tBatch Accuracy: 97.070312\n","Train\t\tEpoch: 65 \tBatch 1/4 (25%) \tBatch Loss: 0.117711 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 65 \tBatch 2/4 (50%) \tBatch Loss: 0.164952 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 65 \tBatch 3/4 (75%) \tBatch Loss: 0.120275 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 65 \tBatch 4/4 (100%) \tBatch Loss: 0.159195 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 66 \tBatch 1/4 (25%) \tBatch Loss: 0.174636 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 66 \tBatch 2/4 (50%) \tBatch Loss: 0.126338 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 66 \tBatch 3/4 (75%) \tBatch Loss: 0.138706 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 66 \tBatch 4/4 (100%) \tBatch Loss: 0.081936 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 67 \tBatch 1/4 (25%) \tBatch Loss: 0.092636 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 67 \tBatch 2/4 (50%) \tBatch Loss: 0.099990 \tBatch Accuracy: 98.046875\n","Train\t\tEpoch: 67 \tBatch 3/4 (75%) \tBatch Loss: 0.125576 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 67 \tBatch 4/4 (100%) \tBatch Loss: 0.215150 \tBatch Accuracy: 96.289062\n","Train\t\tEpoch: 68 \tBatch 1/4 (25%) \tBatch Loss: 0.126757 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 68 \tBatch 2/4 (50%) \tBatch Loss: 0.163540 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 68 \tBatch 3/4 (75%) \tBatch Loss: 0.126949 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 68 \tBatch 4/4 (100%) \tBatch Loss: 0.136074 \tBatch Accuracy: 95.898438\n","Train\t\tEpoch: 69 \tBatch 1/4 (25%) \tBatch Loss: 0.092005 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 69 \tBatch 2/4 (50%) \tBatch Loss: 0.148012 \tBatch Accuracy: 96.484375\n","Train\t\tEpoch: 69 \tBatch 3/4 (75%) \tBatch Loss: 0.141224 \tBatch Accuracy: 96.354167\n","Train\t\tEpoch: 69 \tBatch 4/4 (100%) \tBatch Loss: 0.130583 \tBatch Accuracy: 96.484375\n","Train\t\tEpoch: 70 \tBatch 1/4 (25%) \tBatch Loss: 0.142610 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 70 \tBatch 2/4 (50%) \tBatch Loss: 0.128212 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 70 \tBatch 3/4 (75%) \tBatch Loss: 0.163479 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 70 \tBatch 4/4 (100%) \tBatch Loss: 0.115031 \tBatch Accuracy: 97.070312\n","Train\t\tEpoch: 71 \tBatch 1/4 (25%) \tBatch Loss: 0.115262 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 71 \tBatch 2/4 (50%) \tBatch Loss: 0.113620 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 71 \tBatch 3/4 (75%) \tBatch Loss: 0.161753 \tBatch Accuracy: 97.135417\n","Train\t\tEpoch: 71 \tBatch 4/4 (100%) \tBatch Loss: 0.087337 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 72 \tBatch 1/4 (25%) \tBatch Loss: 0.140636 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 72 \tBatch 2/4 (50%) \tBatch Loss: 0.125819 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 72 \tBatch 3/4 (75%) \tBatch Loss: 0.166481 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 72 \tBatch 4/4 (100%) \tBatch Loss: 0.123538 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 73 \tBatch 1/4 (25%) \tBatch Loss: 0.101639 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 73 \tBatch 2/4 (50%) \tBatch Loss: 0.108015 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 73 \tBatch 3/4 (75%) \tBatch Loss: 0.133338 \tBatch Accuracy: 97.395833\n","Train\t\tEpoch: 73 \tBatch 4/4 (100%) \tBatch Loss: 0.109225 \tBatch Accuracy: 97.070312\n","Train\t\tEpoch: 74 \tBatch 1/4 (25%) \tBatch Loss: 0.090777 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 74 \tBatch 2/4 (50%) \tBatch Loss: 0.155227 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 74 \tBatch 3/4 (75%) \tBatch Loss: 0.109555 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 74 \tBatch 4/4 (100%) \tBatch Loss: 0.112662 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 75 \tBatch 1/4 (25%) \tBatch Loss: 0.078409 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 75 \tBatch 2/4 (50%) \tBatch Loss: 0.143769 \tBatch Accuracy: 98.046875\n","Train\t\tEpoch: 75 \tBatch 3/4 (75%) \tBatch Loss: 0.128443 \tBatch Accuracy: 97.135417\n","Train\t\tEpoch: 75 \tBatch 4/4 (100%) \tBatch Loss: 0.161038 \tBatch Accuracy: 96.289062\n","Train\t\tEpoch: 76 \tBatch 1/4 (25%) \tBatch Loss: 0.073358 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 76 \tBatch 2/4 (50%) \tBatch Loss: 0.161717 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 76 \tBatch 3/4 (75%) \tBatch Loss: 0.132029 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 76 \tBatch 4/4 (100%) \tBatch Loss: 0.073259 \tBatch Accuracy: 97.460938\n","Train\t\tEpoch: 77 \tBatch 1/4 (25%) \tBatch Loss: 0.117551 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 77 \tBatch 2/4 (50%) \tBatch Loss: 0.180244 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 77 \tBatch 3/4 (75%) \tBatch Loss: 0.094697 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 77 \tBatch 4/4 (100%) \tBatch Loss: 0.087399 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 78 \tBatch 1/4 (25%) \tBatch Loss: 0.074309 \tBatch Accuracy: 99.218750\n","Train\t\tEpoch: 78 \tBatch 2/4 (50%) \tBatch Loss: 0.096828 \tBatch Accuracy: 98.828125\n","Train\t\tEpoch: 78 \tBatch 3/4 (75%) \tBatch Loss: 0.122603 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 78 \tBatch 4/4 (100%) \tBatch Loss: 0.176056 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 79 \tBatch 1/4 (25%) \tBatch Loss: 0.128650 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 79 \tBatch 2/4 (50%) \tBatch Loss: 0.095388 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 79 \tBatch 3/4 (75%) \tBatch Loss: 0.136085 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 79 \tBatch 4/4 (100%) \tBatch Loss: 0.102282 \tBatch Accuracy: 97.070312\n","Train\t\tEpoch: 80 \tBatch 1/4 (25%) \tBatch Loss: 0.123408 \tBatch Accuracy: 96.093750\n","Train\t\tEpoch: 80 \tBatch 2/4 (50%) \tBatch Loss: 0.139956 \tBatch Accuracy: 96.484375\n","Train\t\tEpoch: 80 \tBatch 3/4 (75%) \tBatch Loss: 0.111060 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 80 \tBatch 4/4 (100%) \tBatch Loss: 0.107141 \tBatch Accuracy: 96.679688\n","Train\t\tEpoch: 81 \tBatch 1/4 (25%) \tBatch Loss: 0.075995 \tBatch Accuracy: 99.218750\n","Train\t\tEpoch: 81 \tBatch 2/4 (50%) \tBatch Loss: 0.112200 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 81 \tBatch 3/4 (75%) \tBatch Loss: 0.175122 \tBatch Accuracy: 96.614583\n","Train\t\tEpoch: 81 \tBatch 4/4 (100%) \tBatch Loss: 0.095808 \tBatch Accuracy: 96.679688\n","Train\t\tEpoch: 82 \tBatch 1/4 (25%) \tBatch Loss: 0.122865 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 82 \tBatch 2/4 (50%) \tBatch Loss: 0.088752 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 82 \tBatch 3/4 (75%) \tBatch Loss: 0.125100 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 82 \tBatch 4/4 (100%) \tBatch Loss: 0.110828 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 83 \tBatch 1/4 (25%) \tBatch Loss: 0.159816 \tBatch Accuracy: 94.531250\n","Train\t\tEpoch: 83 \tBatch 2/4 (50%) \tBatch Loss: 0.103571 \tBatch Accuracy: 96.484375\n","Train\t\tEpoch: 83 \tBatch 3/4 (75%) \tBatch Loss: 0.075036 \tBatch Accuracy: 97.135417\n","Train\t\tEpoch: 83 \tBatch 4/4 (100%) \tBatch Loss: 0.084104 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 84 \tBatch 1/4 (25%) \tBatch Loss: 0.102617 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 84 \tBatch 2/4 (50%) \tBatch Loss: 0.132217 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 84 \tBatch 3/4 (75%) \tBatch Loss: 0.094564 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 84 \tBatch 4/4 (100%) \tBatch Loss: 0.120403 \tBatch Accuracy: 97.460938\n","Train\t\tEpoch: 85 \tBatch 1/4 (25%) \tBatch Loss: 0.086296 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 85 \tBatch 2/4 (50%) \tBatch Loss: 0.090100 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 85 \tBatch 3/4 (75%) \tBatch Loss: 0.090659 \tBatch Accuracy: 97.916667\n","Train\t\tEpoch: 85 \tBatch 4/4 (100%) \tBatch Loss: 0.098534 \tBatch Accuracy: 97.851562\n","Train\t\tEpoch: 86 \tBatch 1/4 (25%) \tBatch Loss: 0.096926 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 86 \tBatch 2/4 (50%) \tBatch Loss: 0.119465 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 86 \tBatch 3/4 (75%) \tBatch Loss: 0.127427 \tBatch Accuracy: 97.916667\n","Train\t\tEpoch: 86 \tBatch 4/4 (100%) \tBatch Loss: 0.081963 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 87 \tBatch 1/4 (25%) \tBatch Loss: 0.131406 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 87 \tBatch 2/4 (50%) \tBatch Loss: 0.081251 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 87 \tBatch 3/4 (75%) \tBatch Loss: 0.118423 \tBatch Accuracy: 97.395833\n","Train\t\tEpoch: 87 \tBatch 4/4 (100%) \tBatch Loss: 0.095443 \tBatch Accuracy: 97.070312\n","Train\t\tEpoch: 88 \tBatch 1/4 (25%) \tBatch Loss: 0.063041 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 88 \tBatch 2/4 (50%) \tBatch Loss: 0.075834 \tBatch Accuracy: 98.828125\n","Train\t\tEpoch: 88 \tBatch 3/4 (75%) \tBatch Loss: 0.119081 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 88 \tBatch 4/4 (100%) \tBatch Loss: 0.100125 \tBatch Accuracy: 98.242188\n","Train\t\tEpoch: 89 \tBatch 1/4 (25%) \tBatch Loss: 0.072253 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 89 \tBatch 2/4 (50%) \tBatch Loss: 0.077107 \tBatch Accuracy: 98.828125\n","Train\t\tEpoch: 89 \tBatch 3/4 (75%) \tBatch Loss: 0.103198 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 89 \tBatch 4/4 (100%) \tBatch Loss: 0.081608 \tBatch Accuracy: 98.046875\n","Train\t\tEpoch: 90 \tBatch 1/4 (25%) \tBatch Loss: 0.094477 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 90 \tBatch 2/4 (50%) \tBatch Loss: 0.085804 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 90 \tBatch 3/4 (75%) \tBatch Loss: 0.141014 \tBatch Accuracy: 97.135417\n","Train\t\tEpoch: 90 \tBatch 4/4 (100%) \tBatch Loss: 0.087105 \tBatch Accuracy: 97.460938\n","Train\t\tEpoch: 91 \tBatch 1/4 (25%) \tBatch Loss: 0.077263 \tBatch Accuracy: 99.218750\n","Train\t\tEpoch: 91 \tBatch 2/4 (50%) \tBatch Loss: 0.073769 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 91 \tBatch 3/4 (75%) \tBatch Loss: 0.090820 \tBatch Accuracy: 98.697917\n","Train\t\tEpoch: 91 \tBatch 4/4 (100%) \tBatch Loss: 0.112097 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 92 \tBatch 1/4 (25%) \tBatch Loss: 0.109657 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 92 \tBatch 2/4 (50%) \tBatch Loss: 0.070226 \tBatch Accuracy: 98.437500\n","Train\t\tEpoch: 92 \tBatch 3/4 (75%) \tBatch Loss: 0.086814 \tBatch Accuracy: 98.177083\n","Train\t\tEpoch: 92 \tBatch 4/4 (100%) \tBatch Loss: 0.095398 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 93 \tBatch 1/4 (25%) \tBatch Loss: 0.080777 \tBatch Accuracy: 99.218750\n","Train\t\tEpoch: 93 \tBatch 2/4 (50%) \tBatch Loss: 0.097285 \tBatch Accuracy: 98.046875\n","Train\t\tEpoch: 93 \tBatch 3/4 (75%) \tBatch Loss: 0.126379 \tBatch Accuracy: 98.177083\n","Train\t\tEpoch: 93 \tBatch 4/4 (100%) \tBatch Loss: 0.096247 \tBatch Accuracy: 98.046875\n","Train\t\tEpoch: 94 \tBatch 1/4 (25%) \tBatch Loss: 0.134131 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 94 \tBatch 2/4 (50%) \tBatch Loss: 0.074736 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 94 \tBatch 3/4 (75%) \tBatch Loss: 0.071104 \tBatch Accuracy: 97.916667\n","Train\t\tEpoch: 94 \tBatch 4/4 (100%) \tBatch Loss: 0.083812 \tBatch Accuracy: 97.460938\n","Train\t\tEpoch: 95 \tBatch 1/4 (25%) \tBatch Loss: 0.129706 \tBatch Accuracy: 95.312500\n","Train\t\tEpoch: 95 \tBatch 2/4 (50%) \tBatch Loss: 0.078290 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 95 \tBatch 3/4 (75%) \tBatch Loss: 0.092040 \tBatch Accuracy: 97.395833\n","Train\t\tEpoch: 95 \tBatch 4/4 (100%) \tBatch Loss: 0.108908 \tBatch Accuracy: 97.070312\n","Train\t\tEpoch: 96 \tBatch 1/4 (25%) \tBatch Loss: 0.071500 \tBatch Accuracy: 99.218750\n","Train\t\tEpoch: 96 \tBatch 2/4 (50%) \tBatch Loss: 0.084794 \tBatch Accuracy: 98.828125\n","Train\t\tEpoch: 96 \tBatch 3/4 (75%) \tBatch Loss: 0.121125 \tBatch Accuracy: 97.395833\n","Train\t\tEpoch: 96 \tBatch 4/4 (100%) \tBatch Loss: 0.118073 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 97 \tBatch 1/4 (25%) \tBatch Loss: 0.098798 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 97 \tBatch 2/4 (50%) \tBatch Loss: 0.087718 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 97 \tBatch 3/4 (75%) \tBatch Loss: 0.084821 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 97 \tBatch 4/4 (100%) \tBatch Loss: 0.078624 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 98 \tBatch 1/4 (25%) \tBatch Loss: 0.068699 \tBatch Accuracy: 99.218750\n","Train\t\tEpoch: 98 \tBatch 2/4 (50%) \tBatch Loss: 0.128553 \tBatch Accuracy: 98.046875\n","Train\t\tEpoch: 98 \tBatch 3/4 (75%) \tBatch Loss: 0.097904 \tBatch Accuracy: 98.177083\n","Train\t\tEpoch: 98 \tBatch 4/4 (100%) \tBatch Loss: 0.118558 \tBatch Accuracy: 97.851562\n","Train\t\tEpoch: 99 \tBatch 1/4 (25%) \tBatch Loss: 0.112979 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 99 \tBatch 2/4 (50%) \tBatch Loss: 0.102597 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 99 \tBatch 3/4 (75%) \tBatch Loss: 0.106189 \tBatch Accuracy: 97.395833\n","Train\t\tEpoch: 99 \tBatch 4/4 (100%) \tBatch Loss: 0.076194 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 100 \tBatch 1/4 (25%) \tBatch Loss: 0.105324 \tBatch Accuracy: 96.875000\n","Train\t\tEpoch: 100 \tBatch 2/4 (50%) \tBatch Loss: 0.095514 \tBatch Accuracy: 97.265625\n","Train\t\tEpoch: 100 \tBatch 3/4 (75%) \tBatch Loss: 0.091535 \tBatch Accuracy: 97.656250\n","Train\t\tEpoch: 100 \tBatch 4/4 (100%) \tBatch Loss: 0.100180 \tBatch Accuracy: 97.460938\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# initialize model\n","model = MLP().to(device)\n","\n","# optimizer\n","optimizer = optim.SGD(model.parameters(),\n","                      lr=lr,\n","                      momentum=momentum,\n","                      weight_decay=weight_decay)\n","\n","# very useful functions\n","def list_to_vector(list_):\n","    return torch.cat([x.view(-1) for x in list_])\n","\n","def vector_to_list(vector):\n","    list_ = []\n","    counter = 0\n","    for param in list(model.parameters()):\n","        list_.append(vector[counter:counter+torch.numel(param)].view(param.shape))\n","        counter += torch.numel(param)\n","    return list_\n","\n","# total_number_of_parameters\n","p = sum(param.numel() for param in model.parameters() if param.requires_grad)\n","\n","\n","def calculate_Hessian_spectrum(title):\n","    def Hessian_vector_multiplication(vector):\n","        Hv = 0\n","        N = 0\n","        for images, labels in train_loader_2:\n","            N += images.shape[0]\n","            images, labels = images.to(device), labels.to(device) \n","\n","            # images (128, 8^2)\n","            # labels (128,)\n","            \n","            logits = model(images) # (128, 10)\n","            loss = loss_function_2(logits, labels)\n","\n","            # TASK 1: ADD CODE HERE\n","            gradient = torch.autograd.grad(outputs=loss,\n","                                           inputs=model.parameters(),\n","                                           grad_outputs=None,\n","                                           create_graph=True)\n","            gradient = list_to_vector(gradient)\n","\n","            hessian =  torch.autograd.grad(outputs=gradient,\n","                                           inputs=model.parameters(),\n","                                           grad_outputs=vector)\n","            Hv += list_to_vector(hessian)\n","\n","        return Hv/N\n","\n","    def get_Hessian_column(i):\n","        # TASK 2: ADD CODE HERE\n","        v = torch.zeros(p).to(device)\n","        v[i] = 1.0\n","\n","        column = Hessian_vector_multiplication(v)\n","        return column\n","\n","    # TASK 3: ADD CODE HERE\n","    H = torch.cat([get_Hessian_column(i) for i in range(p)]).view(p, p)\n","\n","\n","    # plot spectrum\n","    plt.figure()\n","    eigval,_ = torch.eig(H)\n","    plt.hist(eigval[:,0].detach().cpu(), bins=50)\n","    plt.ylim([0,10])\n","    plt.title(title)\n","\n","\n","calculate_Hessian_spectrum('Hessian spectrum before training')\n","\n","# iterate over epochs\n","for epoch in range(1, epochs+1):\n","    model.train()\n","\n","    accuracy = 0\n","    N = 0\n","\n","    # iterate over train data\n","    for batch_idx, (images, labels) in enumerate(train_loader, start=1):\n","        images, labels = images.to(device), labels.to(device)\n","        \n","        # forward pass\n","        logits = model(images)\n","        loss = loss_function(logits, labels)\n","\n","        # backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # check if predicted labels are equal to true labels\n","        predicted_labels = torch.argmax(logits,dim=1)\n","        accuracy += torch.sum((predicted_labels==labels).float()).item()\n","        N += images.shape[0]\n","\n","        print('Train\\t\\tEpoch: {} \\t'\n","              'Batch {}/{} ({:.0f}%) \\t'\n","              'Batch Loss: {:.6f} \\t'\n","              'Batch Accuracy: {:.6f}'.format(\n","                  epoch,\n","                  batch_idx,\n","                  len(train_loader),\n","                  100. * batch_idx / len(train_loader),\n","                  loss.item(),\n","                  100. * accuracy/N))\n","        \n","calculate_Hessian_spectrum('Hessian spectrum after training')\n","\n","# TASK 4: \n","# Throughout the epochs of SGD, the bulk of the Hessian becomes concetrated \n","# around 0, more outliers are emerge from the bulk, and the outliers increase in\n","# magnitude."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1XqBmQ2UweDe32dc8y03DMWjSxiZaxYkr","timestamp":1668460925543}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.6"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
